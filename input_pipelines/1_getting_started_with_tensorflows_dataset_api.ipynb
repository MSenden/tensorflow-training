{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with TensorFlow's `Dataset` API\n",
    "\n",
    "This notebook contains examples on how to build simple input pipelines with TensorFlow's [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data/) API. The examples are based on contructing `Dataset` objects from Numpy arrays in memory, which is intended to be used only with very small datasets as it can be considerably inefficient.\n",
    "\n",
    "More info can be found on the session [Importing Data](https://www.tensorflow.org/guide/datasets) on TensorFlow's page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fake data\n",
    "nsamples = 10\n",
    "nfeatures = 4\n",
    "x_numpy = np.random.random((nsamples, nfeatures))\n",
    "y_numpy = x_numpy.sum(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a `Dataset` object\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_numpy, y_numpy))\n",
    "dataset = dataset.shuffle(10)\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.repeat(1)\n",
    "\n",
    "# * Dataset.repeat() concatenates the datataset without signaling the end of one epoch\n",
    "#   and the beginning of the next one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[0.52729416 0.97212842 0.79189043 0.11363075]]    y: [2]\n",
      "x: [[0.44317303 0.70935323 0.82828039 0.05453286]]    y: [2]\n",
      "x: [[0.5501465  0.13939612 0.32231135 0.52412096]]    y: [1]\n",
      "x: [[0.63984006 0.58797306 0.71099367 0.61624241]]    y: [2]\n",
      "x: [[0.09530047 0.28822325 0.69780745 0.84440639]]    y: [1]\n",
      "x: [[0.05906955 0.33904709 0.58170577 0.24772649]]    y: [1]\n",
      "x: [[0.73532572 0.13725345 0.08542806 0.76036736]]    y: [1]\n",
      "x: [[0.47149137 0.94588893 0.36952536 0.93342537]]    y: [2]\n",
      "x: [[0.29603562 0.24451967 0.96109423 0.48680933]]    y: [1]\n",
      "x: [[0.79008348 0.84817151 0.19547031 0.15326672]]    y: [1]\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset:\n",
    "    print(f'x: {x}    y: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[0.29603562 0.24451967 0.96109423 0.48680933]]    y: [1]\n",
      "x: [[0.63984006 0.58797306 0.71099367 0.61624241]]    y: [2]\n",
      "x: [[0.52729416 0.97212842 0.79189043 0.11363075]]    y: [2]\n",
      "x: [[0.5501465  0.13939612 0.32231135 0.52412096]]    y: [1]\n",
      "x: [[0.44317303 0.70935323 0.82828039 0.05453286]]    y: [2]\n"
     ]
    }
   ],
   "source": [
    "# iterate up to the 5th sample\n",
    "for x, y in dataset.take(5):\n",
    "    print(f'x: {x}    y: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `Dataset` object can be created also from Tensor objects\n",
    "\n",
    "If the input pipeline depends now on TensorFlow operations, like on the followin cell, for instance, we need to use an **initializable iterator** instead of a **one-shot** one and run `sess.run(iterator.initializer)` befor start iterating. This will perform the graph operations (in this case evalate the tesnors) and that will be needed in the pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = tf.random.uniform([nsamples, nfeatures])\n",
    "y_tensor = tf.cast(tf.reduce_sum(x_tensor, axis=1), tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_tensor, y_tensor))\n",
    "dataset = dataset.shuffle(10)\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.repeat(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[0.60480237 0.37253392 0.01995909 0.73342705]]    y: [1]\n",
      "x: [[0.15328169 0.34407985 0.48509598 0.39430058]]    y: [1]\n",
      "x: [[0.40143    0.2087518  0.45996332 0.683092  ]]    y: [1]\n",
      "x: [[0.37643218 0.7631918  0.7444774  0.6310526 ]]    y: [2]\n",
      "x: [[0.5774617  0.06088769 0.42384326 0.81501126]]    y: [1]\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(5):\n",
    "    print(f'x: {x}    y: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`tf.data.Dataset.from_tensor_slices`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices) embeds the features and labels arrays in your TensorFlow graph as `tf.constant` operations. This works well for a small dataset, but wastes memory because the contents of the array will be copied multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data transformations to the pipeline\n",
    "\n",
    "Lest's say that for our problem it is beneficial to center the features between -0.5 and 0.5. Also, we would like to transform the labels from integers to one-hot encoded. This is can be donde with `Dataset`'s method `map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following transformations are quite simple and can be done\n",
    "# on a single function, but we will use two different functions\n",
    "# to show how operations can be pipelined.\n",
    "\n",
    "def center(*row):\n",
    "    features = row[0] - 0.5\n",
    "    label = row[1]\n",
    "    return features, label\n",
    "\n",
    "def make_on_hot_labels(features, label):\n",
    "    return features, tf.one_hot(label, 4)\n",
    "\n",
    "# simpler with `dataset = dataset.filter(lambda f, l: tf.equal(l, 1))`\n",
    "def filter_labels(features, label):\n",
    "    return tf.equal(label, 1)\n",
    "\n",
    "# simpler with `dataset = dataset.filter(lambda f, l: tf.greater(f[0], 0)`\n",
    "def filter_features(features, label):\n",
    "    return tf.greater(features[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_numpy, y_numpy))\n",
    "dataset = dataset.filter(filter_labels)\n",
    "dataset = dataset.map(center)\n",
    "dataset = dataset.filter(filter_features)\n",
    "dataset = dataset.map(make_on_hot_labels)\n",
    "dataset = dataset.shuffle(150)\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.repeat(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[ 0.29008348  0.34817151 -0.30452969 -0.34673328]]    y: [[0. 1. 0. 0.]]\n",
      "x: [[ 0.0501465  -0.36060388 -0.17768865  0.02412096]]    y: [[0. 1. 0. 0.]]\n",
      "x: [[ 0.23532572 -0.36274655 -0.41457194  0.26036736]]    y: [[0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(5):\n",
    "    print(f'x: {x}    y: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giving names to `Dataset` components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices({'features': x_numpy, 'label': y_numpy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center(row):\n",
    "    features = row['features'] - 0.5\n",
    "    label = row['label']\n",
    "    return {'features': features, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices({'features': x_numpy, 'label': y_numpy})\n",
    "dataset = dataset.map(center)\n",
    "dataset = dataset.shuffle(150)\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.repeat(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[ 0.0501465  -0.36060388 -0.17768865  0.02412096]]    y: [1]\n",
      "x: [[ 0.29008348  0.34817151 -0.30452969 -0.34673328]]    y: [1]\n",
      "x: [[-0.44093045 -0.16095291  0.08170577 -0.25227351]]    y: [1]\n",
      "x: [[ 0.02729416  0.47212842  0.29189043 -0.38636925]]    y: [2]\n",
      "x: [[-0.02850863  0.44588893 -0.13047464  0.43342537]]    y: [2]\n"
     ]
    }
   ],
   "source": [
    "for d in dataset.take(5):\n",
    "    print(f\"x: {d['features']}    y: {d['label']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-multigpu",
   "language": "python",
   "name": "tf-multigpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

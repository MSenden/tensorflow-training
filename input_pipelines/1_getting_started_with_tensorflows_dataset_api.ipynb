{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with TensorFlow's `Dataset` API\n",
    "\n",
    "In this notebook we use TensorFlow's [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data/) API  to build simple input pipelines from Numpy and TensorFlow arrays existing in memory. This is intended to be used only with very small datasets as it can be considerably inefficient.\n",
    "\n",
    "More info can be found on the session [Importing Data](https://www.tensorflow.org/guide/datasets) on TensorFlow's page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fake data\n",
    "nsamples = 10\n",
    "nfeatures = 4\n",
    "x_numpy = np.random.random((nsamples, nfeatures))\n",
    "y_numpy = x_numpy.sum(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a `Dataset` object\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_numpy, y_numpy))\n",
    "dataset = dataset.shuffle(10)\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.repeat(1)\n",
    "\n",
    "# * Dataset.repeat() concatenates the datataset without signaling the end of one epoch\n",
    "#   and the beginning of the next one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[0.78139481 0.11883897 0.39035306 0.73005025]]    y: [2]\n",
      "x: [[0.51803594 0.029389   0.51314648 0.63139709]]    y: [1]\n",
      "x: [[0.22394586 0.9510952  0.12551951 0.54944123]]    y: [1]\n",
      "x: [[0.50468981 0.41202756 0.25616242 0.55185019]]    y: [1]\n",
      "x: [[0.2047827  0.72270374 0.85931468 0.79648837]]    y: [2]\n",
      "x: [[0.39116994 0.34961736 0.56749722 0.67636049]]    y: [1]\n",
      "x: [[0.39408979 0.58097187 0.31183686 0.78895149]]    y: [2]\n",
      "x: [[0.26150226 0.24383822 0.24565584 0.89782191]]    y: [1]\n",
      "x: [[0.94700325 0.25707502 0.85429373 0.37009758]]    y: [2]\n",
      "x: [[0.84791543 0.05778967 0.14045354 0.57825393]]    y: [1]\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset:\n",
    "    print(f'x: {x}    y: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[0.51803594 0.029389   0.51314648 0.63139709]]    y: [1]\n",
      "x: [[0.39408979 0.58097187 0.31183686 0.78895149]]    y: [2]\n",
      "x: [[0.39116994 0.34961736 0.56749722 0.67636049]]    y: [1]\n",
      "x: [[0.22394586 0.9510952  0.12551951 0.54944123]]    y: [1]\n",
      "x: [[0.2047827  0.72270374 0.85931468 0.79648837]]    y: [2]\n"
     ]
    }
   ],
   "source": [
    "# iterate up to the 5th sample\n",
    "for x, y in dataset.take(5):\n",
    "    print(f'x: {x}    y: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `Dataset` object can be created also from TensorFlow tensor objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = tf.random.uniform([nsamples, nfeatures])\n",
    "y_tensor = tf.cast(tf.reduce_sum(x_tensor, axis=1), tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_tensor, y_tensor))\n",
    "dataset = dataset.shuffle(10)\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.repeat(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[0.8927978  0.441705   0.5889245  0.17077637]]    y: [2]\n",
      "x: [[0.74003947 0.9098822  0.01213014 0.5557623 ]]    y: [2]\n",
      "x: [[0.7819412  0.7896348  0.13750732 0.45953274]]    y: [2]\n",
      "x: [[0.36963928 0.7769023  0.36441612 0.05384433]]    y: [1]\n",
      "x: [[0.580734   0.79456425 0.9809855  0.44709933]]    y: [2]\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(5):\n",
    "    print(f'x: {x}    y: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`tf.data.Dataset.from_tensor_slices`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices) embeds the features and labels arrays in your TensorFlow graph as `tf.constant` operations. This works well for a small dataset, but wastes memory because the contents of the array will be copied multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding data transformations to the pipeline\n",
    "\n",
    "Let's say that for our problem it is beneficial to center the features between -0.5 and 0.5. Also, we would like to transform the labels from integers to one-hot encoded. This is can be done with `Dataset`'s method `map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following transformations are quite simple and can be done\n",
    "# on a single function, but we will use two different functions\n",
    "# to show how operations can be put together as a pipeline.\n",
    "\n",
    "def center(*row):\n",
    "    features = row[0] - 0.5\n",
    "    label = row[1]\n",
    "    return features, label\n",
    "\n",
    "def make_on_hot_labels(features, label):\n",
    "    return features, tf.one_hot(label, 4)\n",
    "\n",
    "# simpler with `dataset = dataset.filter(lambda f, l: tf.equal(l, 1))`\n",
    "def filter_labels(features, label):\n",
    "    return tf.equal(label, 1)\n",
    "\n",
    "# simpler with `dataset = dataset.filter(lambda f, l: tf.greater(f[0], 0)`\n",
    "def filter_features(features, label):\n",
    "    return tf.greater(features[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_numpy, y_numpy))\n",
    "dataset = dataset.filter(filter_labels)\n",
    "dataset = dataset.map(center)\n",
    "dataset = dataset.filter(filter_features)\n",
    "dataset = dataset.map(make_on_hot_labels)\n",
    "dataset = dataset.shuffle(150)\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.repeat(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[ 0.34791543 -0.44221033 -0.35954646  0.07825393]]    y: [[0. 1. 0. 0.]]\n",
      "x: [[ 0.00468981 -0.08797244 -0.24383758  0.05185019]]    y: [[0. 1. 0. 0.]]\n",
      "x: [[ 0.01803594 -0.470611    0.01314648  0.13139709]]    y: [[0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(5):\n",
    "    print(f'x: {x}    y: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giving names to `Dataset` components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices({'features': x_numpy, 'label': y_numpy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center(row):\n",
    "    features = row['features'] - 0.5\n",
    "    label = row['label']\n",
    "    return {'features': features, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices({'features': x_numpy, 'label': y_numpy})\n",
    "dataset = dataset.map(center)\n",
    "dataset = dataset.shuffle(10)\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.repeat(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[-0.10883006 -0.15038264  0.06749722  0.17636049]]    y: [1]\n",
      "x: [[ 0.00468981 -0.08797244 -0.24383758  0.05185019]]    y: [1]\n",
      "x: [[-0.23849774 -0.25616178 -0.25434416  0.39782191]]    y: [1]\n",
      "x: [[ 0.44700325 -0.24292498  0.35429373 -0.12990242]]    y: [2]\n",
      "x: [[ 0.01803594 -0.470611    0.01314648  0.13139709]]    y: [1]\n"
     ]
    }
   ],
   "source": [
    "for d in dataset.take(5):\n",
    "    print(f\"x: {d['features']}    y: {d['label']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-multigpu",
   "language": "python",
   "name": "tf-multigpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

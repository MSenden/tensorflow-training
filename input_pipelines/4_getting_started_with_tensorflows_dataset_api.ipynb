{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with TensorFlow's `Dataset` API (continuation)\n",
    "\n",
    "In this notebook we will learn how to divide the dataset over the ranks in distributed training.\n",
    "\n",
    "Let's run this notebook in two nodes and see what happens with the data on each worker. In distributed training one can use [`tf.data.Dataset.shard`]( https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shard) to divide the dataset over the ranks, otherwise the same data might be sent to each of the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipcmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPCluster is ready! (8 seconds)\n"
     ]
    }
   ],
   "source": [
    "%ipcluster start -n 2 --mpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import horovod.tensorflow.keras as hvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "hvd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "def dataset_generator():\n",
    "    \"\"\"A data-producing logic\"\"\"\n",
    "    for i in range(8):\n",
    "        yield (i, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "    x: 0    y: 0\n",
      "    x: 1    y: 1\n",
      "    x: 2    y: 2\n",
      "    x: 3    y: 3\n",
      "    x: 4    y: 4\n",
      "    x: 5    y: 5\n",
      "    x: 6    y: 6\n",
      "    x: 7    y: 7\n",
      "[stdout:1] \n",
      "    x: 0    y: 0\n",
      "    x: 1    y: 1\n",
      "    x: 2    y: 2\n",
      "    x: 3    y: 3\n",
      "    x: 4    y: 4\n",
      "    x: 5    y: 5\n",
      "    x: 6    y: 6\n",
      "    x: 7    y: 7\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "for x, y in dataset_generator():\n",
    "    print((f'    x: {x}    y: {y}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "    x: [0 1]    y: [0 1]\n",
      "    x: [4 5]    y: [4 5]\n",
      "    x: [0 1]    y: [0 1]\n",
      "    x: [4 5]    y: [4 5]\n",
      "[stdout:1] \n",
      "    x: [2 3]    y: [2 3]\n",
      "    x: [6 7]    y: [6 7]\n",
      "    x: [2 3]    y: [2 3]\n",
      "    x: [6 7]    y: [6 7]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "# batch after shard or shard after bash?\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(dataset_generator, output_types=(tf.int32, tf.int32))\n",
    "dataset = dataset.batch(2)\n",
    "dataset = dataset.shard(hvd.size(), hvd.rank())\n",
    "dataset = dataset.repeat(2)\n",
    "\n",
    "for x, y in dataset:\n",
    "    print(f'    x: {x}    y: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:6]: \u001b[0m(2, 0)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-08-26T21:08:48.120760",
      "data": {},
      "engine_id": 0,
      "engine_uuid": "21ea853a-8514d5b9cd753358c7a9f111",
      "error": null,
      "execute_input": "hvd.size(), hvd.rank()\n",
      "execute_result": {
       "data": {
        "text/plain": "(2, 0)"
       },
       "execution_count": 6,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "05d4e24d-2376ffff38980507c1f31c29_11",
      "outputs": [],
      "received": "2020-08-26T21:08:48.123250",
      "started": "2020-08-26T21:08:48.113592",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-08-26T21:08:48.111408"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:6]: \u001b[0m(2, 1)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-08-26T21:08:48.120510",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "80dfc0f2-a94526389e155724c1e3a00a",
      "error": null,
      "execute_input": "hvd.size(), hvd.rank()\n",
      "execute_result": {
       "data": {
        "text/plain": "(2, 1)"
       },
       "execution_count": 6,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "05d4e24d-2376ffff38980507c1f31c29_12",
      "outputs": [],
      "received": "2020-08-26T21:08:48.122340",
      "started": "2020-08-26T21:08:48.113694",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-08-26T21:08:48.111567"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "hvd.size(), hvd.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ipcluster stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-multigpu",
   "language": "python",
   "name": "tf-multigpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

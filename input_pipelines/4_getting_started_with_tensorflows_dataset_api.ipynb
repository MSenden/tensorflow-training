{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with TensorFlow's `Dataset` API (continuation)\n",
    "\n",
    "In this notebook we will learn how to divide the dataset over the ranks in distributed training.\n",
    "\n",
    "Let's run this notebook in two nodes and see what happens with the data on each worker. In distributed training one can use [`tf.data.Dataset.shard`]( https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shard) to divide the dataset over the ranks, otherwise the same data will be sent to each of the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipcmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPCluster is ready! (3 seconds)\n"
     ]
    }
   ],
   "source": [
    "%ipcluster start -n 2 --mpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import horovod.tensorflow.keras as hvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "hvd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:3]: \u001b[0m(2, 0)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-03T09:34:59.110702",
      "data": {},
      "engine_id": 0,
      "engine_uuid": "476ad38a-65357b09f5a8b32b40f7d60a",
      "error": null,
      "execute_input": "hvd.size(), hvd.rank()\n",
      "execute_result": {
       "data": {
        "text/plain": "(2, 0)"
       },
       "execution_count": 3,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "b35d8918-3157d894bc8a27d51071395f_5",
      "outputs": [],
      "received": "2020-09-03T09:34:59.113119",
      "started": "2020-09-03T09:34:59.103959",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-03T09:34:59.102030"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:3]: \u001b[0m(2, 1)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-03T09:34:59.110916",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "8d3a1242-ed8377b2d0b6ebdc513bf019",
      "error": null,
      "execute_input": "hvd.size(), hvd.rank()\n",
      "execute_result": {
       "data": {
        "text/plain": "(2, 1)"
       },
       "execution_count": 3,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "b35d8918-3157d894bc8a27d51071395f_6",
      "outputs": [],
      "received": "2020-09-03T09:34:59.114557",
      "started": "2020-09-03T09:34:59.104191",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-03T09:34:59.102189"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "hvd.size(), hvd.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "def dataset_generator():\n",
    "    \"\"\"A data-producing logic\"\"\"\n",
    "    for i in range(8):\n",
    "        yield (i, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "    x: 0    y: 0\n",
      "    x: 1    y: 1\n",
      "    x: 2    y: 2\n",
      "    x: 3    y: 3\n",
      "    x: 4    y: 4\n",
      "    x: 5    y: 5\n",
      "    x: 6    y: 6\n",
      "    x: 7    y: 7\n",
      "[stdout:1] \n",
      "    x: 0    y: 0\n",
      "    x: 1    y: 1\n",
      "    x: 2    y: 2\n",
      "    x: 3    y: 3\n",
      "    x: 4    y: 4\n",
      "    x: 5    y: 5\n",
      "    x: 6    y: 6\n",
      "    x: 7    y: 7\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "for x, y in dataset_generator():\n",
    "    print((f'    x: {x}    y: {y}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Exercise</mark>: Batch after shard or shard after bash? Consider both options on the following pipeline and see what's the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "    x: [0 1]    y: [0 1]\n",
      "    x: [4 5]    y: [4 5]\n",
      "    x: [0 1]    y: [0 1]\n",
      "    x: [4 5]    y: [4 5]\n",
      "[stdout:1] \n",
      "    x: [2 3]    y: [2 3]\n",
      "    x: [6 7]    y: [6 7]\n",
      "    x: [2 3]    y: [2 3]\n",
      "    x: [6 7]    y: [6 7]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(dataset_generator, output_types=(tf.int32, tf.int32))\n",
    "dataset = dataset.batch(2)\n",
    "dataset = dataset.shard(hvd.size(), hvd.rank())\n",
    "dataset = dataset.repeat(2)\n",
    "\n",
    "for x, y in dataset:\n",
    "    print(f'    x: {x}    y: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ipcluster stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-multigpu",
   "language": "python",
   "name": "tf-multigpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

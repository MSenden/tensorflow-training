{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with ipcmagic and TensorFlow-2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPCluster is ready! (7 seconds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipcmagic\n",
    "import ipyparallel as ipp\n",
    "\n",
    "%ipcluster start -n 2 --mpi\n",
    "\n",
    "rc = ipp.Client()\n",
    "rc.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:1]: \u001b[0m'2.2.0'"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-03T13:51:56.317351",
      "data": {},
      "engine_id": 0,
      "engine_uuid": "542f1c6a-7bdceaaaf22fb3eb488bcb86",
      "error": null,
      "execute_input": "import os\nimport math\nimport json\nimport numpy as np\n\nimport tensorflow as tf\ntf.__version__\n",
      "execute_result": {
       "data": {
        "text/plain": "'2.2.0'"
       },
       "execution_count": 1,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "046d8075-1773fd2a2cbd22406869b6a0_1",
      "outputs": [],
      "received": "2020-09-03T13:51:56.319752",
      "started": "2020-09-03T13:51:48.687280",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-03T13:51:48.684925"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:1]: \u001b[0m'2.2.0'"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-03T13:51:56.296597",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "1e70f88c-70706651a39f0665010e3cbd",
      "error": null,
      "execute_input": "import os\nimport math\nimport json\nimport numpy as np\n\nimport tensorflow as tf\ntf.__version__\n",
      "execute_result": {
       "data": {
        "text/plain": "'2.2.0'"
       },
       "execution_count": 1,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "046d8075-1773fd2a2cbd22406869b6a0_2",
      "outputs": [],
      "received": "2020-09-03T13:51:56.299114",
      "started": "2020-09-03T13:51:48.687188",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-03T13:51:48.685165"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:2]: \u001b[0m\n",
       "('nid06663',\n",
       " [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')])"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-03T13:51:56.602057",
      "data": {},
      "engine_id": 0,
      "engine_uuid": "542f1c6a-7bdceaaaf22fb3eb488bcb86",
      "error": null,
      "execute_input": "import socket\nsocket.gethostname(), tf.config.list_physical_devices('GPU')\n",
      "execute_result": {
       "data": {
        "text/plain": "('nid06663',\n [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')])"
       },
       "execution_count": 2,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "046d8075-1773fd2a2cbd22406869b6a0_3",
      "outputs": [],
      "received": "2020-09-03T13:51:56.604668",
      "started": "2020-09-03T13:51:56.328050",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-03T13:51:56.325969"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:2]: \u001b[0m\n",
       "('nid06664',\n",
       " [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')])"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-03T13:51:56.596607",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "1e70f88c-70706651a39f0665010e3cbd",
      "error": null,
      "execute_input": "import socket\nsocket.gethostname(), tf.config.list_physical_devices('GPU')\n",
      "execute_result": {
       "data": {
        "text/plain": "('nid06664',\n [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')])"
       },
       "execution_count": 2,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "046d8075-1773fd2a2cbd22406869b6a0_4",
      "outputs": [],
      "received": "2020-09-03T13:51:56.599915",
      "started": "2020-09-03T13:51:56.327860",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-03T13:51:56.326106"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "import socket\n",
    "socket.gethostname(), tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# generally MultiWorkerMirroredStrategy requires 'TF_CONFIG' to be set, but in our case\n",
    "# SlurmClusterResolver takes care of all the configuration\n",
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(\n",
    "    cluster_resolver=tf.distribute.cluster_resolver.SlurmClusterResolver(),\n",
    "    communication=tf.distribute.experimental.CollectiveCommunication.NCCL,\n",
    ")\n",
    "\n",
    "# os.environ['TF_CONFIG'] = json.dumps({\n",
    "#     'cluster': {\n",
    "#         'worker': [f\"{os.environ['SLURM_JOB_NODELIST'][:4]}{node}:8888\"\n",
    "#                    for node in os.environ['SLURM_JOB_NODELIST'][5:-1].split('-')]\n",
    "#     },\n",
    "#     'task': {'type': 'worker', 'index': os.environ['SLURM_NODEID']}\n",
    "# })\n",
    "# os.environ['TF_CONFIG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:4]: \u001b[0m(0, 300, 0.060000000000000005)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-03T13:51:56.760646",
      "data": {},
      "engine_id": 0,
      "engine_uuid": "542f1c6a-7bdceaaaf22fb3eb488bcb86",
      "error": null,
      "execute_input": "num_workers = int(os.environ['SLURM_NNODES'])\nnode_id = int(os.environ['SLURM_NODEID'])\n\nper_worker_batch_size = 300\n# Here the batch size scales up by number of workers since \n# `tf.data.Dataset.batch` expects the global batch size.\nbatch_size = per_worker_batch_size * num_workers\n\nlearning_rate = 1e-4 * batch_size\n\nnode_id, per_worker_batch_size, learning_rate\n",
      "execute_result": {
       "data": {
        "text/plain": "(0, 300, 0.060000000000000005)"
       },
       "execution_count": 4,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "046d8075-1773fd2a2cbd22406869b6a0_7",
      "outputs": [],
      "received": "2020-09-03T13:51:56.765459",
      "started": "2020-09-03T13:51:56.757071",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-03T13:51:56.755103"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:4]: \u001b[0m(1, 300, 0.060000000000000005)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-03T13:51:56.761639",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "1e70f88c-70706651a39f0665010e3cbd",
      "error": null,
      "execute_input": "num_workers = int(os.environ['SLURM_NNODES'])\nnode_id = int(os.environ['SLURM_NODEID'])\n\nper_worker_batch_size = 300\n# Here the batch size scales up by number of workers since \n# `tf.data.Dataset.batch` expects the global batch size.\nbatch_size = per_worker_batch_size * num_workers\n\nlearning_rate = 1e-4 * batch_size\n\nnode_id, per_worker_batch_size, learning_rate\n",
      "execute_result": {
       "data": {
        "text/plain": "(1, 300, 0.060000000000000005)"
       },
       "execution_count": 4,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "046d8075-1773fd2a2cbd22406869b6a0_8",
      "outputs": [],
      "received": "2020-09-03T13:51:56.767056",
      "started": "2020-09-03T13:51:56.757279",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-03T13:51:56.755299"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "num_workers = int(os.environ['SLURM_NNODES'])\n",
    "node_id = int(os.environ['SLURM_NODEID'])\n",
    "\n",
    "per_worker_batch_size = 300\n",
    "# Here the batch size scales up by number of workers since \n",
    "# `tf.data.Dataset.batch` expects the global batch size.\n",
    "batch_size = per_worker_batch_size * num_workers\n",
    "\n",
    "learning_rate = 1e-4 * batch_size\n",
    "\n",
    "node_id, per_worker_batch_size, learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                62730     \n",
      "=================================================================\n",
      "Total params: 100,682\n",
      "Trainable params: 100,362\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "[stdout:1] \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                62730     \n",
      "=================================================================\n",
      "Total params: 100,682\n",
      "Trainable params: 100,362\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "def build_and_compile_cnn_model(learning_rate=learning_rate):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(28, 28)),\n",
    "        tf.keras.layers.Reshape(target_shape=(28, 28, 1)), # Convolutional layers expect a channel dimension\n",
    "\n",
    "        tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.BatchNormalization(name='bn0'),\n",
    "\n",
    "        tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.BatchNormalization(name='bn1'),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10),\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    # Model building/compiling need to be within `strategy.scope()`.\n",
    "    multi_worker_model = build_and_compile_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:6]: \u001b[0m(60000, 10000)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-03T13:51:59.554796",
      "data": {},
      "engine_id": 0,
      "engine_uuid": "542f1c6a-7bdceaaaf22fb3eb488bcb86",
      "error": null,
      "execute_input": "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\ntrain_size = len(y_train)\nvalid_size = len(y_test)\n\n# The `x` arrays are in uint8 and have values in the range [0, 255].\n# We need to convert them to float32 with values in the range [0, 1]\ntrain_dataset = (tf.data.Dataset\n                   .from_tensor_slices((x_train / np.float32(255), y_train.astype(np.int32)))\n                   .shuffle(train_size)\n                   .repeat()\n                   .batch(batch_size, drop_remainder=True))\n\nvalid_dataset = (tf.data.Dataset\n                   .from_tensor_slices((x_test / np.float32(255), y_test.astype(np.int32)))\n                   .batch(batch_size, drop_remainder=False))\n\n# In multi-worker training with MultiWorkerMirroredStrategy, sharding the dataset\n# is needed to ensure convergence and performance. However, note that in code here,\n# the datasets are directly passed to model.fit() without needing to shard; this is\n# because tf.distribute.Strategy API takes care of the dataset sharding automatically.\n\ntrain_size, valid_size\n",
      "execute_result": {
       "data": {
        "text/plain": "(60000, 10000)"
       },
       "execution_count": 6,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "046d8075-1773fd2a2cbd22406869b6a0_11",
      "outputs": [],
      "received": "2020-09-03T13:51:59.556500",
      "started": "2020-09-03T13:51:58.994923",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-03T13:51:58.992878"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:6]: \u001b[0m(60000, 10000)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-03T13:51:59.551664",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "1e70f88c-70706651a39f0665010e3cbd",
      "error": null,
      "execute_input": "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\ntrain_size = len(y_train)\nvalid_size = len(y_test)\n\n# The `x` arrays are in uint8 and have values in the range [0, 255].\n# We need to convert them to float32 with values in the range [0, 1]\ntrain_dataset = (tf.data.Dataset\n                   .from_tensor_slices((x_train / np.float32(255), y_train.astype(np.int32)))\n                   .shuffle(train_size)\n                   .repeat()\n                   .batch(batch_size, drop_remainder=True))\n\nvalid_dataset = (tf.data.Dataset\n                   .from_tensor_slices((x_test / np.float32(255), y_test.astype(np.int32)))\n                   .batch(batch_size, drop_remainder=False))\n\n# In multi-worker training with MultiWorkerMirroredStrategy, sharding the dataset\n# is needed to ensure convergence and performance. However, note that in code here,\n# the datasets are directly passed to model.fit() without needing to shard; this is\n# because tf.distribute.Strategy API takes care of the dataset sharding automatically.\n\ntrain_size, valid_size\n",
      "execute_result": {
       "data": {
        "text/plain": "(60000, 10000)"
       },
       "execution_count": 6,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "046d8075-1773fd2a2cbd22406869b6a0_12",
      "outputs": [],
      "received": "2020-09-03T13:51:59.554203",
      "started": "2020-09-03T13:51:58.995148",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-03T13:51:58.993034"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_size = len(y_train)\n",
    "valid_size = len(y_test)\n",
    "\n",
    "# The `x` arrays are in uint8 and have values in the range [0, 255].\n",
    "# We need to convert them to float32 with values in the range [0, 1]\n",
    "train_dataset = (tf.data.Dataset\n",
    "                   .from_tensor_slices((x_train / np.float32(255), y_train.astype(np.int32)))\n",
    "                   .shuffle(train_size)\n",
    "                   .repeat()\n",
    "                   .batch(batch_size, drop_remainder=True))\n",
    "\n",
    "valid_dataset = (tf.data.Dataset\n",
    "                   .from_tensor_slices((x_test / np.float32(255), y_test.astype(np.int32)))\n",
    "                   .batch(batch_size, drop_remainder=False))\n",
    "\n",
    "# In multi-worker training with MultiWorkerMirroredStrategy, sharding the dataset\n",
    "# is needed to ensure convergence and performance. However, note that in code here,\n",
    "# the datasets are directly passed to model.fit() without needing to shard; this is\n",
    "# because tf.distribute.Strategy API takes care of the dataset sharding automatically.\n",
    "\n",
    "train_size, valid_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[output:0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "engine": 0,
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[output:1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAHbUlEQVR4nO3dX6jfdR3H8c/3nGlzedy62AyaOtxMs3L+qZWQK6RCRISgcGJ1kYVpTYosYhLhn2ygN4HZson9kcy8KVx/JbqobM5KYmmQpaQusREz9n87O98uQuji/N6HnT/+Xjs9Hnfbi99v35vnPnA+nN+v6/u+AXlGhv0AwOTECaHECaHECaHECaHECaHECaHEOc90XXdG13UHuq67b9jPwsyIc/75amvtsWE/BDMnznmk67p1rbWXWmu/GPazMHPinCe6rjuptXZza+0zw34WZoc4549bWmv39H3/3LAfhNmxYNgPwMx1XXdua+3drbXzhv0szB5xzg/vaq2taK0923Vda62d2Fob7bru7L7vzx/iczEDnV8ZO/Z1XbeotXbS//zVDe2/sV7b9/3OoTwUM+bknAf6vt/XWtv38p+7rtvTWjsgzGObkxNC+WkthBInhBInhBInhCp/WvuekQ/4aRHMsYcnHuwm+3snJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4RaMOwHYHZNXHReud/yrc3lfvU31g/cln/5kWk9E9Pj5IRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ7jnnmb9+pP7/9u0LR8t95MhsPk2OBctfV+4n3H+w3Pdesn/gNrF377SeaSpOTgglTgglTgglTgglTgglTgjlKuUY86+rLyz3E8Z2l/vK73+83Ffd8ehRP1OCBacsL/c1W54u9y8ufbLcLx1de9TPNFNOTgglTgglTgglTgglTgglTgglTgjlnjPM0xvre8zfXHVHub/j19eV+6pPbT3qZ0pw4LI15b7ro/X97o+muMfcdWRfufd9X+5zwckJocQJocQJocQJocQJocQJocQJodxzzoGRhQvL/dlPnz9w2zbFPeZrRl9d7mO/XFTuycYvvmDgdtGtvy1fe+uy7eW+6aX6ozHv3Xh5uS/ZXf/7c8HJCaHECaHECaHECaHECaHECaHECaHcc86BbuVp5f7E+ruKtb6nXPnAFJ87u3lbuQ/TVF/Dd/mdPx+4fWLJc+VrN7x4Trn/8bL6c22X7Hjl7zGn4uSEUOKEUOKEUOKEUOKEUOKEUOKEUO45p2HineeV+1Vff2ja733+zdeW+1kP/b3cxyeOTPvfnmuLH6g/G7a6y1y97crytcvX159bO77j+XJP5OSEUOKEUOKEUOKEUOKEUOKEUK5SJjMyWs6Hb9xV7leMvVDuZ957/cBtxd31r3wN86pkwWtPLvcX3nd6uX/zlNvL/cx7PjtwW7VpiiukHf8o92ORkxNCiRNCiRNCiRNCiRNCiRNCiRNCueecxM5r1pT7H970tXLfN9GX+/iiwftT964uX3vJ2U+W+1xae1J9B7tu7Gfl/pfDXbmv+MLgj6ccL185Pzk5IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZR7zknsX1bfx01l0cjx5f63KzbN6P1TPT++p9w/fOMN5b64bZ3NxznmOTkhlDghlDghlDghlDghlDghlDghlHvOMIf7+nNpD/aHy/1V3XHlflxXfyZvZd/EoXJ//4Yp7jHvc495NJycEEqcEEqcEEqcEEqcEEqcEEqcEMo95yRO/cnucj992TXlPvbU9O8Sl/1+f7mP/Orxcv/nD88q98ff+r1y/8HeEwduX1l/ZfnaxT91jzmbnJwQSpwQSpwQSpwQSpwQSpwQylXKZLZtL+cz6m/Cm1PP3HZhuT/xljuneIf6mmfjTR8cuLkqeWU5OSGUOCGUOCGUOCGUOCGUOCGUOCGUe84wL32ovsf89rr6HvPFI/WvnL337s+V+ynffbTceeU4OSGUOCGUOCGUOCGUOCGUOCGUOCGUe84h6C5448DtwS/dXr721AWDP7qytdZW3V9/Dd/KWx8pd3I4OSGUOCGUOCGUOCGUOCGUOCGUOCGUe845MLp0abmfu3nw5+JOdY/5yR1vK/dV9+8p975cSeLkhFDihFDihFDihFDihFDihFCuUqZhZGys3P/9nXq/7eSHB277Jg6Vr91+0+pyX/i7IX4/IbPKyQmhxAmhxAmhxAmhxAmhxAmhxAmh3HNOw/PXvrnct59z17Tf++LPX1/ui7dsnfZ7c2xxckIocUIocUIocUIocUIocUIocUIo95yTGRkt59MufabcD/aHy/2sH183cHvDlj+Xrz1SrswnTk4IJU4IJU4IJU4IJU4IJU4IJU4I5Z5zEt1IV+7Hj4yX+58O1V+09/qPPTZwc4/Jy5ycEEqcEEqcEEqcEEqcEEqcEEqcEMo95yT68foec+/aneW+oa2Zzcfh/5STE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0J1fV9/XR0wHE5OCCVOCCVOCCVOCCVOCCVOCPUfSsMNjbf17zIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "engine": 1,
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "# show first training image on each node\n",
    "for images, labels in train_dataset.take(1):\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.imshow(images[0])\n",
    "    plt.axis('off')\n",
    "    plt.title(str(labels[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] Training for 100 steps per epoch across 2 nodes\n",
      "[stdout:1] Training for 100 steps per epoch across 2 nodes\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "# Keras' `model.fit()` trains the model with specified number of steps and epochs across all nodes\n",
    "steps_per_epoch = train_size // batch_size\n",
    "validation_steps = math.ceil(valid_size / batch_size)\n",
    "print(f'Training for {steps_per_epoch} steps per epoch across {num_workers} nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Epoch 1/7\n",
      "100/100 [==============================] - 2s 22ms/step - accuracy: 0.8429 - loss: 4.2645 - val_accuracy: 0.7705 - val_loss: 1.8419\n",
      "Epoch 2/7\n",
      "100/100 [==============================] - 1s 9ms/step - accuracy: 0.9652 - loss: 0.1204 - val_accuracy: 0.9417 - val_loss: 0.2198\n",
      "Epoch 3/7\n",
      "100/100 [==============================] - 1s 9ms/step - accuracy: 0.9731 - loss: 0.0907 - val_accuracy: 0.9677 - val_loss: 0.1072\n",
      "Epoch 4/7\n",
      "100/100 [==============================] - 1s 9ms/step - accuracy: 0.9742 - loss: 0.0936 - val_accuracy: 0.9773 - val_loss: 0.0740\n",
      "Epoch 5/7\n",
      "100/100 [==============================] - 1s 9ms/step - accuracy: 0.9797 - loss: 0.0680 - val_accuracy: 0.9806 - val_loss: 0.0625\n",
      "Epoch 6/7\n",
      "100/100 [==============================] - 1s 9ms/step - accuracy: 0.9815 - loss: 0.0599 - val_accuracy: 0.9824 - val_loss: 0.0548\n",
      "Epoch 7/7\n",
      "100/100 [==============================] - 1s 9ms/step - accuracy: 0.9841 - loss: 0.0524 - val_accuracy: 0.9800 - val_loss: 0.0630\n",
      "[stdout:1] \n",
      "Epoch 1/7\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 4.2645 - accuracy: 0.8429 - val_loss: 1.8419 - val_accuracy: 0.7705\n",
      "Epoch 2/7\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1204 - accuracy: 0.9652 - val_loss: 0.2198 - val_accuracy: 0.9417\n",
      "Epoch 3/7\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0907 - accuracy: 0.9731 - val_loss: 0.1072 - val_accuracy: 0.9677\n",
      "Epoch 4/7\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0936 - accuracy: 0.9742 - val_loss: 0.0740 - val_accuracy: 0.9773\n",
      "Epoch 5/7\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0680 - accuracy: 0.9797 - val_loss: 0.0625 - val_accuracy: 0.9806\n",
      "Epoch 6/7\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0599 - accuracy: 0.9815 - val_loss: 0.0548 - val_accuracy: 0.9824\n",
      "Epoch 7/7\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0524 - accuracy: 0.9841 - val_loss: 0.0630 - val_accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "multi_worker_model.fit(train_dataset,\n",
    "                       epochs=7,\n",
    "                       steps_per_epoch=steps_per_epoch,\n",
    "                       validation_data=valid_dataset,\n",
    "                       validation_steps=validation_steps,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - accuracy: 0.9800 - loss: 0.0630\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "multi_worker_model.evaluate(valid_dataset, batch_size=batch_size, steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ipcluster stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniconda-sc2020",
   "language": "python",
   "name": "miniconda-sc2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with ipcmagic and TensorFlow-2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPCluster is ready! (6 seconds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipcmagic\n",
    "import ipyparallel as ipp\n",
    "\n",
    "%ipcluster start -n 2 --mpi\n",
    "\n",
    "rc = ipp.Client()\n",
    "rc.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:1]: \u001b[0m'2.3.0'"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-05T15:47:28.155499",
      "data": {},
      "engine_id": 0,
      "engine_uuid": "ec0d4f6d-fd8652393716c7bb6aeaa92c",
      "error": null,
      "execute_input": "import os\nimport math\nimport json\nimport numpy as np\n\nimport tensorflow as tf\ntf.__version__\n",
      "execute_result": {
       "data": {
        "text/plain": "'2.3.0'"
       },
       "execution_count": 1,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "1ee9f28b-b3c21332cd8a481176aa994f_1",
      "outputs": [],
      "received": "2020-09-05T15:47:28.157740",
      "started": "2020-09-05T15:47:21.692305",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-05T15:47:21.690199"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:1]: \u001b[0m'2.3.0'"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-05T15:47:27.928632",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "ba8157f1-dd4d9875df8158faf64bce9a",
      "error": null,
      "execute_input": "import os\nimport math\nimport json\nimport numpy as np\n\nimport tensorflow as tf\ntf.__version__\n",
      "execute_result": {
       "data": {
        "text/plain": "'2.3.0'"
       },
       "execution_count": 1,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "1ee9f28b-b3c21332cd8a481176aa994f_2",
      "outputs": [],
      "received": "2020-09-05T15:47:27.931031",
      "started": "2020-09-05T15:47:21.693128",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-05T15:47:21.690463"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:2]: \u001b[0m\n",
       "('nid06661',\n",
       " [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')])"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-05T15:47:29.447274",
      "data": {},
      "engine_id": 0,
      "engine_uuid": "ec0d4f6d-fd8652393716c7bb6aeaa92c",
      "error": null,
      "execute_input": "import socket\nsocket.gethostname(), tf.config.list_physical_devices('GPU')\n",
      "execute_result": {
       "data": {
        "text/plain": "('nid06661',\n [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')])"
       },
       "execution_count": 2,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "1ee9f28b-b3c21332cd8a481176aa994f_3",
      "outputs": [],
      "received": "2020-09-05T15:47:29.449970",
      "started": "2020-09-05T15:47:28.165901",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-05T15:47:28.163858"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:2]: \u001b[0m\n",
       "('nid06662',\n",
       " [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')])"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-05T15:47:29.536423",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "ba8157f1-dd4d9875df8158faf64bce9a",
      "error": null,
      "execute_input": "import socket\nsocket.gethostname(), tf.config.list_physical_devices('GPU')\n",
      "execute_result": {
       "data": {
        "text/plain": "('nid06662',\n [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')])"
       },
       "execution_count": 2,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "1ee9f28b-b3c21332cd8a481176aa994f_4",
      "outputs": [],
      "received": "2020-09-05T15:47:29.539530",
      "started": "2020-09-05T15:47:28.166114",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-05T15:47:28.164009"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "import socket\n",
    "socket.gethostname(), tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# generally MultiWorkerMirroredStrategy requires 'TF_CONFIG' to be set, but in our case\n",
    "# SlurmClusterResolver takes care of all the configuration\n",
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(\n",
    "    cluster_resolver=tf.distribute.cluster_resolver.SlurmClusterResolver(),\n",
    "    communication=tf.distribute.experimental.CollectiveCommunication.NCCL,\n",
    ")\n",
    "\n",
    "# os.environ['TF_CONFIG'] = json.dumps({\n",
    "#     'cluster': {\n",
    "#         'worker': [f\"{os.environ['SLURM_JOB_NODELIST'][:4]}{node}:8888\"\n",
    "#                    for node in os.environ['SLURM_JOB_NODELIST'][5:-1].split('-')]\n",
    "#     },\n",
    "#     'task': {'type': 'worker', 'index': os.environ['SLURM_NODEID']}\n",
    "# })\n",
    "# os.environ['TF_CONFIG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:4]: \u001b[0m(0, 128, 0.0002)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-05T15:47:31.570500",
      "data": {},
      "engine_id": 0,
      "engine_uuid": "ec0d4f6d-fd8652393716c7bb6aeaa92c",
      "error": null,
      "execute_input": "num_workers = int(os.environ['SLURM_NNODES'])\nnode_id = int(os.environ['SLURM_NODEID'])\n\nper_worker_batch_size = 128\n\n# Here the batch size scales up by number of workers since \n# `tf.data.Dataset.batch` expects the global batch size.\nbatch_size = per_worker_batch_size * num_workers\n\nlearning_rate = 1e-4 * num_workers\n\nnode_id, per_worker_batch_size, learning_rate\n",
      "execute_result": {
       "data": {
        "text/plain": "(0, 128, 0.0002)"
       },
       "execution_count": 4,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "1ee9f28b-b3c21332cd8a481176aa994f_7",
      "outputs": [],
      "received": "2020-09-05T15:47:31.575071",
      "started": "2020-09-05T15:47:31.567153",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-05T15:47:31.565342"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:4]: \u001b[0m(1, 128, 0.0002)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-05T15:47:31.570530",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "ba8157f1-dd4d9875df8158faf64bce9a",
      "error": null,
      "execute_input": "num_workers = int(os.environ['SLURM_NNODES'])\nnode_id = int(os.environ['SLURM_NODEID'])\n\nper_worker_batch_size = 128\n\n# Here the batch size scales up by number of workers since \n# `tf.data.Dataset.batch` expects the global batch size.\nbatch_size = per_worker_batch_size * num_workers\n\nlearning_rate = 1e-4 * num_workers\n\nnode_id, per_worker_batch_size, learning_rate\n",
      "execute_result": {
       "data": {
        "text/plain": "(1, 128, 0.0002)"
       },
       "execution_count": 4,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "1ee9f28b-b3c21332cd8a481176aa994f_8",
      "outputs": [],
      "received": "2020-09-05T15:47:31.573296",
      "started": "2020-09-05T15:47:31.567219",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-05T15:47:31.565679"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "num_workers = int(os.environ['SLURM_NNODES'])\n",
    "node_id = int(os.environ['SLURM_NODEID'])\n",
    "\n",
    "per_worker_batch_size = 128\n",
    "\n",
    "# Here the batch size scales up by number of workers since \n",
    "# `tf.data.Dataset.batch` expects the global batch size.\n",
    "batch_size = per_worker_batch_size * num_workers\n",
    "\n",
    "learning_rate = 1e-4 * num_workers\n",
    "\n",
    "node_id, per_worker_batch_size, learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:5]: \u001b[0m(60000, 10000)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-05T15:47:32.478308",
      "data": {},
      "engine_id": 0,
      "engine_uuid": "ec0d4f6d-fd8652393716c7bb6aeaa92c",
      "error": null,
      "execute_input": "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\ntrain_size = len(y_train)\nvalid_size = len(y_test)\n\n# The `x` arrays are in uint8 and have values in the range [0, 255].\n# We need to convert them to float32 with values in the range [0, 1]\ntrain_dataset = (tf.data.Dataset\n                   .from_tensor_slices((x_train / np.float32(255), y_train.astype(np.int32)))\n                   .shuffle(train_size, seed=42)\n                   .repeat()\n                   .batch(batch_size, drop_remainder=True))\n\nvalid_dataset = (tf.data.Dataset\n                   .from_tensor_slices((x_test / np.float32(255), y_test.astype(np.int32)))\n                   .batch(batch_size, drop_remainder=False))\n\n# In multi-worker training with MultiWorkerMirroredStrategy, sharding the dataset\n# is needed to ensure convergence and performance. However, note that in code here,\n# the datasets are directly passed to model.fit() without needing to shard; this is\n# because tf.distribute.Strategy API takes care of the dataset sharding automatically.\n\ntrain_size, valid_size\n",
      "execute_result": {
       "data": {
        "text/plain": "(60000, 10000)"
       },
       "execution_count": 5,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "1ee9f28b-b3c21332cd8a481176aa994f_9",
      "outputs": [],
      "received": "2020-09-05T15:47:32.480680",
      "started": "2020-09-05T15:47:31.590434",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-05T15:47:31.588702"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:5]: \u001b[0m(60000, 10000)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-05T15:47:32.518513",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "ba8157f1-dd4d9875df8158faf64bce9a",
      "error": null,
      "execute_input": "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\ntrain_size = len(y_train)\nvalid_size = len(y_test)\n\n# The `x` arrays are in uint8 and have values in the range [0, 255].\n# We need to convert them to float32 with values in the range [0, 1]\ntrain_dataset = (tf.data.Dataset\n                   .from_tensor_slices((x_train / np.float32(255), y_train.astype(np.int32)))\n                   .shuffle(train_size, seed=42)\n                   .repeat()\n                   .batch(batch_size, drop_remainder=True))\n\nvalid_dataset = (tf.data.Dataset\n                   .from_tensor_slices((x_test / np.float32(255), y_test.astype(np.int32)))\n                   .batch(batch_size, drop_remainder=False))\n\n# In multi-worker training with MultiWorkerMirroredStrategy, sharding the dataset\n# is needed to ensure convergence and performance. However, note that in code here,\n# the datasets are directly passed to model.fit() without needing to shard; this is\n# because tf.distribute.Strategy API takes care of the dataset sharding automatically.\n\ntrain_size, valid_size\n",
      "execute_result": {
       "data": {
        "text/plain": "(60000, 10000)"
       },
       "execution_count": 5,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "1ee9f28b-b3c21332cd8a481176aa994f_10",
      "outputs": [],
      "received": "2020-09-05T15:47:32.521066",
      "started": "2020-09-05T15:47:31.590510",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-05T15:47:31.588877"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_size = len(y_train)\n",
    "valid_size = len(y_test)\n",
    "\n",
    "# The `x` arrays are in uint8 and have values in the range [0, 255].\n",
    "# We need to convert them to float32 with values in the range [0, 1]\n",
    "train_dataset = (tf.data.Dataset\n",
    "                   .from_tensor_slices((x_train / np.float32(255), y_train.astype(np.int32)))\n",
    "                   .shuffle(train_size, seed=42)\n",
    "                   .repeat()\n",
    "                   .batch(batch_size, drop_remainder=True))\n",
    "\n",
    "valid_dataset = (tf.data.Dataset\n",
    "                   .from_tensor_slices((x_test / np.float32(255), y_test.astype(np.int32)))\n",
    "                   .batch(batch_size, drop_remainder=False))\n",
    "\n",
    "# In multi-worker training with MultiWorkerMirroredStrategy, sharding the dataset\n",
    "# is needed to ensure convergence and performance. However, note that in code here,\n",
    "# the datasets are directly passed to model.fit() without needing to shard; this is\n",
    "# because tf.distribute.Strategy API takes care of the dataset sharding automatically.\n",
    "\n",
    "train_size, valid_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] (256, 28, 28) tf.Tensor([7 2 1 0 4 1 4 9 5 9], shape=(10,), dtype=int32)\n",
      "[stdout:1] (256, 28, 28) tf.Tensor([7 2 1 0 4 1 4 9 5 9], shape=(10,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[output:0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "engine": 0,
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[output:1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "engine": 1,
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "# show first image on each node\n",
    "for images, labels in valid_dataset.take(1):\n",
    "    print(images.shape, labels[:10])\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.imshow(images[0])\n",
    "    plt.axis('off')\n",
    "    plt.title(str(labels[0].numpy()))\n",
    "\n",
    "# the batch is actually the same in both nodes\n",
    "# the sharding happens within model.fit(), which uses strategy.experimental_distribute_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] (128, 28, 28) tf.Tensor([7 2 1 0 4 1 4 9 5 9], shape=(10,), dtype=int32)\n",
      "[stdout:1] (128, 28, 28) tf.Tensor([8 5 6 6 5 7 8 1 0 1], shape=(10,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[output:0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAGxElEQVR4nO3dX6jfdR3H8c93O9vJc2Zl1oxmbthQmqVX9k+CBR0iZHQxDyW0vCmjurAu6iIQgsJIkjCty6LE/nBUCLSCIfRHXCpFM7KBpRLSdLWsbW1uzvPtqovFvu/N8zvb73V+ezxgMM573+/vM855ng/8Pud3fl3f9w3Is2rcCwBOTpwQSpwQSpwQSpwQSpwQSpwQSpwToOu6Q//35+Wu6+4Y97oYzdS4F8Do+r5f97+/d123rrX2XGttYXwrYjnYOSfP9tbavtbar8e9EEYjzslzQ2vt+72fy1zxOp/DydF13cbW2lOttc193z897vUwGjvnZNnRWntImJNBnJPlY6217417ESwPcU6Iruve01rb0DxLOzHEOTluaK3d1/f9wXEvhOXhCSEIZeeEUOKEUOKEUOKEUOUPvs+tmvdsEZxhOxcXupN93M4JocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJoabGvYAzZf8n3j04u2THn8tr9+y7qJwfO7qmnG/4YT2fefbQ4Gzx90+U13LusHNCKHFCKHFCKHFCKHFCKHFCKHFCqIk95/zC538wONs++0J98VtGfPCt9fiZ44cHZ7f//X0jPvjK9ei+jYOz2dteU1479eBvl3s5Y2fnhFDihFDihFDihFDihFDihFDihFBd3/eDw7lV88PDcP+57p2Ds39cWX9PuuBP9X/7hbd25Xztlf8q57e+7b7B2dx5R8prHzi8rpxfOzP8WtFRHemPlfNHjs6W862vemnJj735gU+W88tufGzJ9x63nYsLJ/2CsnNCKHFCKHFCKHFCKHFCKHFCKHFCqIl9PefsPY8Us9Hu/erRLm93vHHr4Owr12yqH/uX9e/cvXXr5iWs6PRMHVks57OP7y3nF/7q3nL+9rXDv+935pn6dwFPIjsnhBInhBInhBInhBInhBInhBInhJrYc85kx597fnA2e+/wrLXWXj7FvWfv2b+EFS2P5z8+/J6orbV2xdr6y+3r/7x8cLbpu0+V1x4vpyuTnRNCiRNCiRNCiRNCiRNCiRNCOUrhtE1tfHM5v/OLd5bzNd3qcr5w+/sHZxfu3VVeO4nsnBBKnBBKnBBKnBBKnBBKnBBKnBDKOSenbc/nNpTzq6frt0b847H67Q1f98ThV7ymSWbnhFDihFDihFDihFDihFDihFDihFDOOTnB0WuvHpz97rpvnOLq6XL6qZtuKufnPfzoKe5/brFzQihxQihxQihxQihxQihxQihxQijnnJzgrx8c/n69rqvPMa9/eq6cz/x8dznvy+m5x84JocQJocQJocQJocQJocQJocQJoZxznmNWnX9+Od/x3ocGZwcWXyyv3XfLpeV8+uhj5ZwT2TkhlDghlDghlDghlDghlDghlKOUc8yTX7qinN//+m8Pzj705Pby2umfOipZTnZOCCVOCCVOCCVOCCVOCCVOCCVOCOWcc8L8+6PvKuePf/ib5fwvx18anB362sXltdNtbznnlbFzQihxQihxQihxQihxQihxQihxQijnnCvM1IY3lfPP3vzjcj7d1Z/yj+zeMTh7w8+8XvNssnNCKHFCKHFCKHFCKHFCKHFCKHFCKOecYbqp+lNy1f3PlvP5dfvL+d0H15fzi24e/n69WF7JcrNzQihxQihxQihxQihxQihxQihHKWmuurwcf3n9XSPd/lu3zJfz1+7eNdL9WT52TgglTgglTgglTgglTgglTgglTgjlnHMMVm+5bHB2449+MtK9t3znM+V8012/Gen+nD12TgglTgglTgglTgglTgglTgglTgjlnHMM9nz6gsHZtpkDI9374l8cq/9B3490f84eOyeEEieEEieEEieEEieEEieEEieEcs55Bry47R3l/MFttxXTmeVdDCuWnRNCiRNCiRNCiRNCiRNCiRNCiRNCOec8A/52zepyfsnU0s8y7z64vpyvOVC/ntOrOVcOOyeEEieEEieEEieEEieEEieEcpQS5qv7t5TzXR/YVM77vX9YxtUwTnZOCCVOCCVOCCVOCCVOCCVOCCVOCNX1xVvCza2a9wojOMN2Li50J/u4nRNCiRNCiRNCiRNCiRNCiRNCiRNCleecwPjYOSGUOCGUOCGUOCGUOCGUOCHUfwHJB9/nWZ1JyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "engine": 0,
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[output:1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "engine": 1,
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "# show first image on each node (from the sharded batch)\n",
    "for images, labels in strategy.experimental_distribute_dataset(valid_dataset.take(1)):\n",
    "    print(images.shape, labels[:10])\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.imshow(images[0])\n",
    "    plt.axis('off')\n",
    "    plt.title(str(labels[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] Training for 234 steps per epoch across 2 nodes\n",
      "[stdout:1] Training for 234 steps per epoch across 2 nodes\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "# Keras' `model.fit()` trains the model with specified number of steps and epochs across all nodes\n",
    "steps_per_epoch = train_size // batch_size\n",
    "validation_steps = math.ceil(valid_size / batch_size)\n",
    "print(f'Training for {steps_per_epoch} steps per epoch across {num_workers} nodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "bn0 (SyncBatchNormalization) (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "bn1 (SyncBatchNormalization) (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                62730     \n",
      "=================================================================\n",
      "Total params: 100,682\n",
      "Trainable params: 100,362\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "[stdout:1] \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "bn0 (SyncBatchNormalization) (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "bn1 (SyncBatchNormalization) (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                62730     \n",
      "=================================================================\n",
      "Total params: 100,682\n",
      "Trainable params: 100,362\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "def build_and_compile_cnn_model(learning_rate=learning_rate):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(28, 28)),\n",
    "        tf.keras.layers.Reshape(target_shape=(28, 28, 1)), # Convolutional layers expect a channel dimension\n",
    "\n",
    "        tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.experimental.SyncBatchNormalization(name='bn0'),\n",
    "\n",
    "        tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.experimental.SyncBatchNormalization(name='bn1'),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10),\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    # Model building/compiling need to be within `strategy.scope()`.\n",
    "    multi_worker_model = build_and_compile_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Epoch 1/3\n",
      "234/234 [==============================] - 3s 12ms/step - loss: 0.4867 - accuracy: 0.8570 - val_loss: 1.7723 - val_accuracy: 0.3064\n",
      "Epoch 2/3\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 0.1923 - accuracy: 0.9470 - val_loss: 0.4668 - val_accuracy: 0.9027\n",
      "Epoch 3/3\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 0.1478 - accuracy: 0.9592 - val_loss: 0.1431 - val_accuracy: 0.9648\n",
      "[stdout:1] \n",
      "Epoch 1/3\n",
      "234/234 [==============================] - 3s 12ms/step - loss: 0.4867 - accuracy: 0.8570 - val_loss: 1.7723 - val_accuracy: 0.3064\n",
      "Epoch 2/3\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 0.1923 - accuracy: 0.9470 - val_loss: 0.4668 - val_accuracy: 0.9027\n",
      "Epoch 3/3\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 0.1478 - accuracy: 0.9592 - val_loss: 0.1431 - val_accuracy: 0.9648\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "fit = multi_worker_model.fit(train_dataset,\n",
    "                             epochs=3,\n",
    "                             steps_per_epoch=steps_per_epoch,\n",
    "                             validation_data=valid_dataset,\n",
    "                             validation_steps=validation_steps,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect BatchNorm Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:11]: \u001b[0m\n",
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([0.00373676, 0.00963929, 0.0049729 , 0.03507098, 0.0040793 ,\n",
       "       0.0530093 , 0.0118209 , 0.04469763, 0.02566126, 0.02563354],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-05T15:47:48.410087",
      "data": {},
      "engine_id": 0,
      "engine_uuid": "ec0d4f6d-fd8652393716c7bb6aeaa92c",
      "error": null,
      "execute_input": "# Batch Normalization statistics (both mean and variance)\n# are slightly different due to the data sharding and sample noise\nbn = multi_worker_model.get_layer('bn0')\nbn.moving_mean[:10]\n",
      "execute_result": {
       "data": {
        "text/plain": "<tf.Tensor: shape=(10,), dtype=float32, numpy=\narray([0.00373676, 0.00963929, 0.0049729 , 0.03507098, 0.0040793 ,\n       0.0530093 , 0.0118209 , 0.04469763, 0.02566126, 0.02563354],\n      dtype=float32)>"
       },
       "execution_count": 11,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "1ee9f28b-b3c21332cd8a481176aa994f_21",
      "outputs": [],
      "received": "2020-09-05T15:47:48.415129",
      "started": "2020-09-05T15:47:48.406023",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-05T15:47:48.404158"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:11]: \u001b[0m\n",
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([0.00373676, 0.00963929, 0.0049729 , 0.03507098, 0.0040793 ,\n",
       "       0.0530093 , 0.0118209 , 0.04469763, 0.02566126, 0.02563354],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-09-05T15:47:48.409754",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "ba8157f1-dd4d9875df8158faf64bce9a",
      "error": null,
      "execute_input": "# Batch Normalization statistics (both mean and variance)\n# are slightly different due to the data sharding and sample noise\nbn = multi_worker_model.get_layer('bn0')\nbn.moving_mean[:10]\n",
      "execute_result": {
       "data": {
        "text/plain": "<tf.Tensor: shape=(10,), dtype=float32, numpy=\narray([0.00373676, 0.00963929, 0.0049729 , 0.03507098, 0.0040793 ,\n       0.0530093 , 0.0118209 , 0.04469763, 0.02566126, 0.02563354],\n      dtype=float32)>"
       },
       "execution_count": 11,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "1ee9f28b-b3c21332cd8a481176aa994f_22",
      "outputs": [],
      "received": "2020-09-05T15:47:48.413298",
      "started": "2020-09-05T15:47:48.406169",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-09-05T15:47:48.404518"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px\n",
    "# Batch Normalization statistics (both mean and variance)\n",
    "# are synchronised across all nodes during the forward pass\n",
    "bn = multi_worker_model.get_layer('bn0')\n",
    "bn.moving_mean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ipcluster stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-multigpu",
   "language": "python",
   "name": "tf-multigpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
